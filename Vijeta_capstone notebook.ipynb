{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "870cc944-5743-4b65-8559-8a22ebb7ce17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.listScopes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fafdd6f6-95cf-4063-8fa0-ef9c049c4aae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mounting ADLS with databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11eb063d-217f-4b49-8871-27cf39eb5508",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "files = dbutils.fs.ls(\"/mnt/vijetaadlscapstone2/Air_quality\")\n",
    "for f in files:\n",
    "    print(f.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "595ccc91-23a1-4d31-aeb9-cb4414d177d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "storage_key = dbutils.secrets.get(scope='vijetanewscopecapstone', key='vijetasecretcapstone')\n",
    "fd_storage_path = \"fs.azure.account.key.vijetaadlscapstone.blob.core.windows.net\"\n",
    "\n",
    "spark.conf.set(fd_storage_path, storage_key)\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "file_path = 'wasbs://capstone2@vijetaadlscapstone.blob.core.windows.net/Air_quality/AirQuality_2025-11-07 11:07:45'\n",
    "\n",
    "df = spark.read.format(\"json\").load(file_path)\n",
    "\n",
    "# Explode the list of dictionaries into rows\n",
    "# df_exploded = df.select(F.explode('records').alias('item'))\n",
    "\n",
    "# If you want to flatten the dictionary fields into columns\n",
    "# df_flat = df_exploded.select('item.*')\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1098d8fc-7569-4968-b493-3d24d24cfa64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "capitals = {\n",
    "  \"Andhra Pradesh\": \"Amaravati\",\n",
    "  \"Arunachal Pradesh\": \"Itanagar\",\n",
    "  \"Assam\": \"Dispur\",\n",
    "  \"Bihar\": \"Patna\",\n",
    "  \"Chhattisgarh\": \"Raipur\",\n",
    "  \"Delhi\": \"New Delhi\",\n",
    "  \"Goa\": \"Panaji\",\n",
    "  \"Gujarat\": \"Gandhinagar\",\n",
    "  \"Haryana\": \"Chandigarh\",\n",
    "  \"Himachal Pradesh\": \"Shimla\",\n",
    "  \"Jharkhand\": \"Ranchi\",\n",
    "  \"Karnataka\": \"Bengaluru\",\n",
    "  \"Kerala\": \"Thiruvananthapuram\",\n",
    "  \"Madhya Pradesh\": \"Bhopal\",\n",
    "  \"Maharashtra\": \"Mumbai\",\n",
    "  \"Manipur\": \"Imphal\",\n",
    "  \"Meghalaya\": \"Shillong\",\n",
    "  \"Mizoram\": \"Aizawl\",\n",
    "  \"Nagaland\": \"Kohima\",\n",
    "  \"Odisha\": \"Bhubaneswar\",\n",
    "  \"Punjab\": \"Chandigarh\",\n",
    "  \"Rajasthan\": \"Jaipur\",\n",
    "  \"Sikkim\": \"Gangtok\",\n",
    "  \"Tamil Nadu\": \"Chennai\",\n",
    "  \"Telangana\": \"Hyderabad\",\n",
    "  \"Tripura\": \"Agartala\",\n",
    "  \"Uttar Pradesh\": \"Lucknow\",\n",
    "  \"Uttarakhand\": \"Dehradun\",\n",
    "  \"West Bengal\": \"Kolkata\"\n",
    "}\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b48fbbf-51be-40ca-8180-08db1e5156ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9876b61-af1b-459d-aa33-498c4f7184fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_capital = spark.createDataFrame(capitals.items(), [\"state\", \"city\"])\n",
    "display(df_capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ac35a88-9b14-4512-8ea2-ccc3e7bf958a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_2 = df.join(df_capital, (df.state == df_capital.state) & (df.city == df_capital.city), \"inner\")\n",
    "display(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5273cf2c-0117-4caa-a4aa-802578aab938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_2 = df_2.drop(df_capital.state,df_capital.city)\n",
    "display(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d55fbd6-341a-4e71-83ee-220020937ab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Removing row level duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fbbdda2-ec21-495b-98db-530bbd541fe6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_2 = df_2.dropDuplicates()\n",
    "display(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57367169-cb15-4c20-81dc-8ad797d3dc66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#All states of India\n",
    "\n",
    "states_all = [\"Andhra Pradesh\",\"Arunachal Pradesh \",\"Assam\",\"Bihar\",\"Chhattisgarh\",\"Delhi\",\"Goa\",\"Gujarat\",\"Haryana\",\"Himachal Pradesh\",\"Jharkhand\",\"Karnataka\",\"Kerala\",\"Madhya Pradesh\",\"Maharashtra\",\"Manipur\",\"Meghalaya\",\"Mizoram\",\"Nagaland\",\"Odisha\",\"Punjab\",\"Rajasthan\",\"Sikkim\",\"Tamil Nadu\",\"Telangana\",\"Tripura\",\"Uttar Pradesh\",\"Uttarakhand\",\"West Bengal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f426270-54f1-461a-b17d-f6598062ef33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#State values\n",
    "\n",
    "df_check = df_2.withColumn(\"state\", F.col(\"state\").isin(states_all))\n",
    " \n",
    "alarm_states = df_check.filter(df_check.state == False)\n",
    " \n",
    "if alarm_states.count() > 0:\n",
    "  print(\"The States are not Correct\")\n",
    "  alarm_states.select(\"state\").distinct().show()\n",
    "else:\n",
    "  print(\"All States are Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccc65745-3abc-4167-a8f2-4d6ccc0be976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lattitude and Longitude (maximum and minimum i.e. -90 to 90 and -180 to 180)\n",
    "\n",
    "df_check = df_2.filter((df_2.latitude.cast(\"Double\") < -90) | (df_2.latitude.cast(\"Double\") > 90) | (df_2.longitude.cast(\"Double\") < -180) | (df_2.longitude.cast(\"Double\") > 180))\n",
    " \n",
    "if df_check.count() > 0:\n",
    "  print(\"The Latitude and Longitude are not Correct\")\n",
    "  df_check.select(\"latitude\", \"longitude\").distinct().show()\n",
    "else:\n",
    "  print(\"All Latitude and Longitude are Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d53655a5-1f5a-41cd-806c-4461862b5891",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ozone, CO & SO2- Transformations\n",
    "\n",
    "# Cleansing Pollutant_Avg\n",
    "df_pollutant = df_2.withColumn(\"pollutant_avg\", F.when(F.col('pollutant_avg') == 'NA', 0).otherwise(F.col('pollutant_avg')))\n",
    " \n",
    "ozone_range = df_pollutant.filter((df_pollutant.pollutant_id == 'OZONE') & (df_pollutant.pollutant_avg.cast(\"Double\") > 100))\n",
    "co_range = df_pollutant.filter((df_pollutant.pollutant_id == 'CO') & (df_pollutant.pollutant_avg.cast(\"Double\") > 7))\n",
    "so2_range = df_pollutant.filter((df_pollutant.pollutant_id == 'SO2') & (df_pollutant.pollutant_avg.cast(\"Double\") > 40))\n",
    " \n",
    "# Join/merge all three columns\n",
    "alarmed_pollutants = ozone_range.union(co_range).union(so2_range)\n",
    " \n",
    "if (alarmed_pollutants.count() > 0):\n",
    "  print(\"The pollutant values are not Correct\")\n",
    "  alarmed_pollutants.select(\"state\", \"city\", \"pollutant_id\", \"pollutant_avg\").distinct().show(150)\n",
    "else:\n",
    "  print(\"All pollutant values are Correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7ab23dc-ff72-4f16-ac0a-151b21d403c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Write to silver (Silver layer transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a64183af-57f8-4907-ad47-cc5badbe0a64",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762517440508}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_2.write.mode(\"overwrite\").format(\"delta\").saveAsTable(\"faampn6.vijeta_schema_airquality.air_quality_silver\")\n",
    "display(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75e09777-ca74-474e-bc20-3f6b523f552b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Adding data fetch time as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef790edb-f60b-48cb-b6b2-da0728ec273e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date\n",
    " \n",
    "df_2 = df_2.withColumn(\"date\", to_date(\"Datafetchtime\"))\n",
    "display(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9ec762e-7342-48fd-a5cb-542bd6bd8cbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    " \n",
    "df_clean = df_2.withColumn(\"pollutant_avg\", F.when(F.col('pollutant_avg') == 'NA', 0).otherwise(F.col('pollutant_avg')))\\\n",
    "    .withColumn(\"pollutant_min\", F.when(F.col('pollutant_min') == 'NA', 0).otherwise(F.col('pollutant_min')))\\\n",
    "    .withColumn(\"pollutant_max\", F.when(F.col('pollutant_max') == 'NA', 0).otherwise(F.col('pollutant_max')))\n",
    "display(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dbbbb23-f1e4-402e-bf5b-6f266fefd349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max, avg\n",
    "df_summary = df_clean.groupBy(\"state\", \"city\", \"pollutant_id\", \"date\").agg(min(\"pollutant_min\").alias(\"Min_Pollutant\"), max(\"pollutant_max\").alias(\"Max_Pollutant\"), avg(\"pollutant_avg\").alias(\"Avg_Pollutant\"))\n",
    "\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f94a6431-60c1-416d-b683-f47714f893f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Saving to Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb40ba8c-a3f0-418a-9c6f-2a33b76805d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_summary.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"faampn6.vijeta_schema_airquality.air_quality_gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf38228d-914f-4ac8-a5ce-281cf16ac051",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_summary.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"hive_metastore.default.Vijeta_air_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b6b93da-93a8-42ab-8fc4-a7b12bc42522",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_gold = spark.read.table(\"faampn6.vijeta_schema_airquality.air_quality_gold\")\n",
    "display(df_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5a7a30f-a1f3-411d-86d3-35c2942de908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Databricks Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "261406c3-c521-46f0-baed-f96ebeae2486",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Prepare data for Sankey diagram\n",
    "states = df_summary.select(\"state\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "cities = df_summary.select(\"city\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "pollutants = df_summary.select(\"pollutant_id\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "state_idx = {k: i for i, k in enumerate(states)}\n",
    "city_idx = {k: i+len(states) for i, k in enumerate(cities)}\n",
    "pollutant_idx = {k: i+len(states)+len(cities) for i, k in enumerate(pollutants)}\n",
    "\n",
    "# State to City links\n",
    "state_city = df_summary.groupBy(\"state\", \"city\").count().collect()\n",
    "links_state_city = [{\n",
    "    \"source\": state_idx[row[\"state\"]],\n",
    "    \"target\": city_idx[row[\"city\"]],\n",
    "    \"value\": row[\"count\"]\n",
    "} for row in state_city]\n",
    "\n",
    "# City to Pollutant links\n",
    "city_pollutant = df_summary.groupBy(\"city\", \"pollutant_id\").count().collect()\n",
    "links_city_pollutant = [{\n",
    "    \"source\": city_idx[row[\"city\"]],\n",
    "    \"target\": pollutant_idx[row[\"pollutant_id\"]],\n",
    "    \"value\": row[\"count\"]\n",
    "} for row in city_pollutant]\n",
    "\n",
    "# Combine all links\n",
    "links = links_state_city + links_city_pollutant\n",
    "\n",
    "label = states + cities + pollutants\n",
    "source = [l[\"source\"] for l in links]\n",
    "target = [l[\"target\"] for l in links]\n",
    "value = [l[\"value\"] for l in links]\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=label\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=source,\n",
    "        target=target,\n",
    "        value=value\n",
    "    ))])\n",
    "\n",
    "fig.update_layout(title_text=\"State → City → Pollutant Sankey Diagram\", font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f858ee4-5f7c-40b8-b042-5e007fa844dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Prepare data for mapping: ensure state names and avg_pollutant are present\n",
    "df_map = df_summary.select(\"state\", \"Avg_Pollutant\").groupBy(\"state\").avg(\"Avg_Pollutant\").withColumnRenamed(\"avg(Avg_Pollutant)\", \"avg_pollutant\")\n",
    "pandas_df = df_map.toPandas()\n",
    "\n",
    "fig = px.choropleth(\n",
    "    pandas_df,\n",
    "    geojson=\"https://raw.githubusercontent.com/plotly/datasets/master/india_states.geojson\",\n",
    "    featureidkey=\"properties.ST_NM\",\n",
    "    locations=\"state\",\n",
    "    color=\"avg_pollutant\",\n",
    "    color_continuous_scale=\"YlOrRd\",\n",
    "    title=\"Average Pollutant by Indian State\"\n",
    ")\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10b93748-6e3c-4cbf-a622-c18707519a38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Prepare data\n",
    "df_map = df_summary.select(\"state\", \"Avg_Pollutant\").groupBy(\"state\").avg(\"Avg_Pollutant\").withColumnRenamed(\"avg(Avg_Pollutant)\", \"avg_pollutant\")\n",
    "pandas_df = df_map.toPandas()\n",
    "\n",
    "# For globe view, we need lat/lon for each state. Example mapping (should be replaced with actual centroids for all states)\n",
    "state_coords = {\n",
    "    \"Andhra Pradesh\": (15.9129, 79.7400),\n",
    "    \"Arunachal Pradesh\": (28.2180, 94.7278),\n",
    "    \"Assam\": (26.2006, 92.9376),\n",
    "    \"Bihar\": (25.0961, 85.3131),\n",
    "    \"Chhattisgarh\": (21.2787, 81.8661),\n",
    "    \"Goa\": (15.2993, 74.1240),\n",
    "    \"Gujarat\": (22.2587, 71.1924),\n",
    "    \"Haryana\": (29.0588, 76.0856),\n",
    "    \"Himachal Pradesh\": (31.1048, 77.1734),\n",
    "    \"Jharkhand\": (23.6102, 85.2799),\n",
    "    \"Karnataka\": (15.3173, 75.7139),\n",
    "    \"Kerala\": (10.8505, 76.2711),\n",
    "    \"Madhya Pradesh\": (22.9734, 78.6569),\n",
    "    \"Maharashtra\": (19.7515, 75.7139),\n",
    "    \"Manipur\": (24.6637, 93.9063),\n",
    "    \"Meghalaya\": (25.4670, 91.3662),\n",
    "    \"Mizoram\": (23.1645, 92.9376),\n",
    "    \"Nagaland\": (26.1584, 94.5624),\n",
    "    \"Odisha\": (20.9517, 85.0985),\n",
    "    \"Punjab\": (31.1471, 75.3412),\n",
    "    \"Rajasthan\": (27.0238, 74.2179),\n",
    "    \"Sikkim\": (27.5330, 88.5122),\n",
    "    \"Tamil Nadu\": (11.1271, 78.6569),\n",
    "    \"Telangana\": (18.1124, 79.0193),\n",
    "    \"Tripura\": (23.9408, 91.9882),\n",
    "    \"Uttar Pradesh\": (26.8467, 80.9462),\n",
    "    \"Uttarakhand\": (30.0668, 79.0193),\n",
    "    \"West Bengal\": (22.9868, 87.8550),\n",
    "    \"Delhi\": (28.7041, 77.1025),\n",
    "    \"Jammu and Kashmir\": (33.7782, 76.5762),\n",
    "    \"Ladakh\": (34.1526, 77.5771),\n",
    "    \"Puducherry\": (11.9416, 79.8083),\n",
    "    \"Chandigarh\": (30.7333, 76.7794),\n",
    "    \"Andaman and Nicobar Islands\": (11.7401, 92.6586),\n",
    "    \"Dadra and Nagar Haveli and Daman and Diu\": (20.1809, 73.0169),\n",
    "    \"Lakshadweep\": (10.5667, 72.6417)\n",
    "}\n",
    "\n",
    "# Add lat/lon to pandas_df\n",
    "pandas_df[\"lat\"] = pandas_df[\"state\"].map(lambda x: state_coords.get(x, (None, None))[0])\n",
    "pandas_df[\"lon\"] = pandas_df[\"state\"].map(lambda x: state_coords.get(x, (None, None))[1])\n",
    "\n",
    "# Drop rows with missing coordinates\n",
    "pandas_df = pandas_df.dropna(subset=[\"lat\", \"lon\"])\n",
    "\n",
    "fig = go.Figure(go.Scattergeo(\n",
    "    lon = pandas_df[\"lon\"],\n",
    "    lat = pandas_df[\"lat\"],\n",
    "    text = pandas_df[\"state\"] + \"<br>Avg Pollutant: \" + pandas_df[\"avg_pollutant\"].round(2).astype(str),\n",
    "    marker = dict(\n",
    "        size = 12,\n",
    "        color = pandas_df[\"avg_pollutant\"],\n",
    "        colorscale = \"YlOrRd\",\n",
    "        colorbar_title = \"Avg Pollutant\",\n",
    "        line_color='black',\n",
    "        line_width=0.5,\n",
    "        sizemode='area'\n",
    "    )\n",
    "))\n",
    "\n",
    "fig.update_geos(\n",
    "    projection_type=\"orthographic\",\n",
    "    showcountries=True,\n",
    "    showcoastlines=True,\n",
    "    showland=True,\n",
    "    landcolor=\"rgb(217, 217, 217)\",\n",
    "    countrycolor=\"rgb(204, 204, 204)\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Globe View: Average Pollutant by Indian State\",\n",
    "    geo=dict(\n",
    "        projection_scale=2.5,\n",
    "        center=dict(lat=22, lon=80)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "793c69f1-aa0d-4921-952e-4fcff3d69dd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Prepare data: average pollutant by state\n",
    "df_map = df_summary.select(\"state\", \"Avg_Pollutant\").groupBy(\"state\").avg(\"Avg_Pollutant\").withColumnRenamed(\"avg(Avg_Pollutant)\", \"avg_pollutant\")\n",
    "pandas_df = df_map.toPandas().sort_values(\"avg_pollutant\", ascending=False)\n",
    "\n",
    "fig = go.Figure(go.Waterfall(\n",
    "    x=pandas_df[\"state\"],\n",
    "    y=pandas_df[\"avg_pollutant\"],\n",
    "    text=pandas_df[\"avg_pollutant\"].round(2).astype(str),\n",
    "    connector={\"line\":{\"color\":\"#0074D9\"}},\n",
    "    decreasing={\"marker\":{\"color\":\"#1f77b4\"}},\n",
    "    increasing={\"marker\":{\"color\":\"#339af0\"}},\n",
    "    totals={\"marker\":{\"color\":\"#003366\"}}\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Waterfall Chart: Average Pollutant by Indian State\",\n",
    "    xaxis_title=\"State\",\n",
    "    yaxis_title=\"Average Pollutant\",\n",
    "    showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Vijeta_capstone notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
